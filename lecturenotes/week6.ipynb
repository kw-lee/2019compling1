{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## http://taewan.kim/post/cnn/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN에는 다음과 같은 용어들이 사용됩니다.\n",
    "\n",
    "* Convolution(합성곱)\n",
    "* 채널(Channel)\n",
    "* 필터(Filter)\n",
    "* 커널(Kernel)\n",
    "* 스트라이드(Strid)\n",
    "* 패딩(Padding)\n",
    "* 피처 맵(Feature Map)\n",
    "* 액티베이션 맵(Activation Map)\n",
    "* 풀링(Pooling) 레이어\n",
    "\n",
    "간략하게 각 용어에 대해서 살펴 보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution\n",
    "\n",
    "### Channel\n",
    "\n",
    "Dimension과 관련이 있음\n",
    "Ex. RGB channel\n",
    "\n",
    "### Filter\n",
    "\n",
    "* feature를 catch\n",
    "* channel 별로 동일한 filter를 적용할 수도, 다르게 할 수도 \n",
    "* 각 channel에 filter를 적용한 뒤, 다 더한 layer를 feature map이라 한다.\n",
    "\n",
    "### Strid\n",
    "\n",
    "필터를 적용하는 위치의 간격\n",
    "\n",
    "### Padding\n",
    "\n",
    "* 데이터 근처에 0으로 채운 pixel들을 추가\n",
    "* Convolution layer를 반복적으로 쌓을 때, 출력크기가 줄어드는 현상을 막기 위해 도입\n",
    "\n",
    "입력이 $(H, W)$, 출력이 $(OH, OW)$, 필터가 $(FH, FW)$, 패딩이 $P$, 스트라이드가 $S$라 했을 때,\n",
    "\\begin{aligned}\n",
    "    OH &= \\frac{H + 2P - FH}{S} + 1, \\\\\n",
    "    OW &= \\frac{W + 2P - FW}{S} + 1.\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooling\n",
    "\n",
    "* 출력 데이터의 크기를 줄이거나 강조할 때 사용\n",
    "* Max pooling, average pooling 과 같은 방법이 있음\n",
    "![](https://taewanmerepo.github.io/2018/02/cnn/maxpulling.png)\n",
    "* pooling 을 이용하면 CNN의 계산량을 줄일 수 있음\n",
    "* 일반적으로는 max pooling을 사용함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 인공 신경망의 총 파라미터는 백만 개가 넘습니다. 예제 CNN 파라미터와 비교하면 10배 이상의 학습 파라미터를 갖습니다. 은닉층을 더 깊게 만들 경우 Fully Connected Neural Network과 CNN과의 학습 파라미터의 차이는 더 급격하게 늘어납니다. CNN은 Fully Connected Neural Network과 비교하여 다음과 같은 특징을 갖습니다.\n",
    "\n",
    "> * CNN은 학습 파라미터 수가 매우 작음\n",
    "> * 학습 파라미터가 작고, 학습이 쉽고 네트워크 처리 속도가 빠름\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* CNN은 언어처리에는 부적합?\n",
    "* 감정분석 등에 사용된다?\n",
    "\n",
    "http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/\n",
    "\n",
    "HW: 두 paper를 읽고 핵심을 요약해서 올리기\n",
    "\n",
    "* https://arxiv.org/abs/1408.5882\n",
    "* https://arxiv.org/abs/1508.06615\n",
    "\n",
    "\n",
    "Yoon Kim. n-gram을 CNN으로"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice\n",
    "\n",
    "[Notebook](../deep-learning-wizard/docs/deep_learning/practical_pytorch/pytorch_convolutional_neuralnetwork.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPU를 쓴 경우 성능이 매우 좋아졌지만, 2개를 쓰면 더 느려졌음 (병목현상이 아닐까; GPU가 너무 좋은듯)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
